{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DATASCI W261: Machine Learning at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write some words to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!echo \"foo foo quux labs foo bar jimi quux jimi jimi\" > WordCount.txt\n",
    "!echo \"foo  jimi jimi\" >> WordCount.txt\n",
    "!echo \"data mining is data science\" >> WordCount.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MrJob class for wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordCount.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile WordCount.py\n",
    "from mrjob.job import MRJob\n",
    "# from mrjob.step import MRStep\n",
    "import re\n",
    " \n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    " \n",
    "class MRWordFreqCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield word.lower(), 1\n",
    "     \n",
    "    def combiner(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    #hello, (1,1,1,1,1,1): using a combiner? NO and YEs\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/mq/yly0yqf16wggskk8bwchkhjmkztgr3/T/WordCount.z001gyq.20160614.180851.220183\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /var/folders/mq/yly0yqf16wggskk8bwchkhjmkztgr3/T/WordCount.z001gyq.20160614.180851.220183/output...\n",
      "\"bar\"\t1\n",
      "\"data\"\t2\n",
      "\"foo\"\t4\n",
      "\"is\"\t1\n",
      "\"jimi\"\t5\n",
      "\"labs\"\t1\n",
      "\"mining\"\t1\n",
      "\"quux\"\t2\n",
      "\"science\"\t1\n",
      "Removing temp directory /var/folders/mq/yly0yqf16wggskk8bwchkhjmkztgr3/T/WordCount.z001gyq.20160614.180851.220183...\n"
     ]
    }
   ],
   "source": [
    "!python WordCount.py  WordCount.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Running step 1 of 1...\n",
      "Creating temp directory /var/folders/mq/yly0yqf16wggskk8bwchkhjmkztgr3/T/WordCount.z001gyq.20160614.180853.764892\n",
      "Streaming final output from mrJobOutput...\n",
      "\"bar\"\t1\n",
      "\"data\"\t2\n",
      "\"foo\"\t4\n",
      "\"is\"\t1\n",
      "\"jimi\"\t5\n",
      "\"labs\"\t1\n",
      "\"mining\"\t1\n",
      "\"quux\"\t2\n",
      "\"science\"\t1\n",
      "Removing temp directory /var/folders/mq/yly0yqf16wggskk8bwchkhjmkztgr3/T/WordCount.z001gyq.20160614.180853.764892...\n"
     ]
    }
   ],
   "source": [
    "!python WordCount.py  WordCount.txt --output-dir mrJobOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "-rw-r--r--  1 z001gyq  staff  41 Jun 14 13:08 part-00000\n",
      "-rw-r--r--  1 z001gyq  staff  41 Jun 14 13:08 part-00001\n",
      "\"bar\"\t1\n",
      "\"data\"\t2\n",
      "\"foo\"\t4\n",
      "\"is\"\t1\n",
      "\"jimi\"\t5\n"
     ]
    }
   ],
   "source": [
    "!ls -l mrJobOutput\n",
    "!cat mrJobOutput/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordCount.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile WordCount.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    " \n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    " \n",
    "class MRWordFreqCount(MRJob):\n",
    "    SORT_VALUES = True\n",
    "    def mapper(self, _, line):\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield word.lower(), 1\n",
    "            \n",
    "    def jobconfqqqq(self):  #assume we had second job to sort the word counts in decreasing order of counts\n",
    "        orig_jobconf = super(MRWordFreqCount, self).jobconf()        \n",
    "        custom_jobconf = {  #key value pairs\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k2,2nr',\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "\n",
    "\n",
    "    def combiner(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    def steps(self):\n",
    "        return [MRStep(\n",
    "                mapper = self.mapper, \n",
    "#                #combiner = self.combiner,\n",
    "                reducer = self.reducer,\n",
    "                #,\n",
    "#                jobconf = self.jobconfqqqq\n",
    " \n",
    "#            jobconf = {'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "#                       'mapred.text.key.comparator.options':'-k1r',\n",
    "#                       'mapred.reduce.tasks' : 1}   \n",
    "       \n",
    "        \n",
    "            )]\n",
    "     \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run the code in command line locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "ignoring partitioner keyword arg (requires real Hadoop): 'org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner'\n",
      "Running step 1 of 1...\n",
      "Creating temp directory /var/folders/mq/yly0yqf16wggskk8bwchkhjmkztgr3/T/WordCount.z001gyq.20160614.180913.070111\n",
      "Streaming final output from mrJobOutput...\n",
      "\"bar\"\t1\n",
      "\"data\"\t2\n",
      "\"foo\"\t4\n",
      "\"is\"\t1\n",
      "\"jimi\"\t5\n",
      "\"labs\"\t1\n",
      "\"mining\"\t1\n",
      "\"quux\"\t2\n",
      "\"science\"\t1\n",
      "Removing temp directory /var/folders/mq/yly0yqf16wggskk8bwchkhjmkztgr3/T/WordCount.z001gyq.20160614.180913.070111...\n"
     ]
    }
   ],
   "source": [
    "!python WordCount.py --jobconf -numReduceTasks=3 WordCount.txt --output-dir mrJobOutput\n",
    "\n",
    "\n",
    "# mr_your_job.py --jobconf mapred.map.tasks=23 --jobconf \n",
    "#> mapred.reduce.tasks=42 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrJobOutput/part-00000 mrJobOutput/part-00001\n",
      "\"bar\"\t1\n",
      "\"data\"\t2\n",
      "\"foo\"\t4\n",
      "\"is\"\t1\n",
      "\"jimi\"\t5\n"
     ]
    }
   ],
   "source": [
    "!ls mrJobOutput/*\n",
    "!cat mrJobOutput/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is straightforward. Mapper outputs (word, 1) key value pairs, and then combiner combines the sum locally. Lastly, Reducer sums them up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code through python driver locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Reminder: You cannot use the programmatic runner functionality in the same file as your job class. That is because the file with the job class is sent to Hadoop to be run. Therefore, the job file cannot attempt to start the Hadoop job, or you would be recursively creating Hadoop jobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use make_runner() to run an MRJob\n",
    "1. seperate driver from mapreduce jobs\n",
    "2. now we can run it within python notebook \n",
    "3. In python, typically one class is in each file. Each mrjob job is a seperate class, should be in a seperate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bar', 1)\n",
      "('data', 2)\n",
      "('foo', 4)\n",
      "('is', 1)\n",
      "('jimi', 5)\n",
      "('labs', 1)\n",
      "('mining', 1)\n",
      "('quux', 2)\n",
      "('science', 1)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from WordCount import MRWordFreqCount\n",
    "mr_job = MRWordFreqCount(args=['WordCount.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code in command line in AWS\n",
    "- Check you configration file path\n",
    "- Create .mrjob.conf\n",
    "- Put your access key info in configuration  file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#.mrjob.conf is on my Dropbox Slides/AWS\n",
    "from mrjob import conf \n",
    "conf.find_mrjob_conf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Create or replace .mrjob.conf file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "runners:\n",
    "    emr:\n",
    "        aws_access_key_id: your_access_key_id\n",
    "        aws_secret_access_key: your_secret_access_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the code in command line in AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Traceback (most recent call last):\n",
      "  File \"WordCount.py\", line 51, in <module>\n",
      "    MRWordFreqCount.run()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/job.py\", line 430, in run\n",
      "    mr_job.execute()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/job.py\", line 448, in execute\n",
      "    super(MRJob, self).execute()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/launch.py\", line 160, in execute\n",
      "    self.run_job()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/launch.py\", line 228, in run_job\n",
      "    with self.make_runner() as runner:\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/job.py\", line 471, in make_runner\n",
      "    return super(MRJob, self).make_runner()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/launch.py\", line 171, in make_runner\n",
      "    return EMRJobRunner(**self.emr_job_runner_kwargs())\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/emr.py\", line 626, in __init__\n",
      "    self._fix_s3_tmp_and_log_uri_opts()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/emr.py\", line 764, in _fix_s3_tmp_and_log_uri_opts\n",
      "    self._set_s3_tmp_dir()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/emr.py\", line 780, in _set_s3_tmp_dir\n",
      "    buckets = self.fs.get_all_buckets()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/fs/s3.py\", line 297, in get_all_buckets\n",
      "    return self.make_s3_conn().get_all_buckets()\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/mrjob/fs/s3.py\", line 225, in make_s3_conn\n",
      "    security_token=self._aws_security_token)\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/boto/__init__.py\", line 141, in connect_s3\n",
      "    return S3Connection(aws_access_key_id, aws_secret_access_key, **kwargs)\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/boto/s3/connection.py\", line 191, in __init__\n",
      "    validate_certs=validate_certs, profile_name=profile_name)\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/boto/connection.py\", line 569, in __init__\n",
      "    host, config, self.provider, self._required_auth_capability())\n",
      "  File \"/Users/z001gyq/anaconda/envs/py27/lib/python2.7/site-packages/boto/auth.py\", line 989, in get_auth_handler\n",
      "    'Check your credentials' % (len(names), str(names)))\n",
      "boto.exception.NoAuthHandlerFound: No handler was ready to authenticate. 1 handlers were checked. ['HmacAuthV1Handler'] Check your credentials\n"
     ]
    }
   ],
   "source": [
    "!python WordCount.py WordCount.txt -r emr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
